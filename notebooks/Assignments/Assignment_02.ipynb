{
  "cells": [
    {
      "metadata": {
        "id": "1d8158dfddb2ac72"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "In this assignment, you will continue with the Bigram Language Model from the Lecture. Make the training loop and inference for the model."
      ],
      "id": "1d8158dfddb2ac72"
    },
    {
      "metadata": {
        "id": "c011cbf15834af26"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "id": "c011cbf15834af26"
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "source": [
        "import os\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from utils import load_text, set_seed"
      ],
      "outputs": [],
      "execution_count": 4
    },
    {
      "metadata": {
        "id": "4a4a0b5274f4dca2"
      },
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "id": "4a4a0b5274f4dca2"
    },
    {
      "metadata": {
        "id": "ef1253f6800c36c1"
      },
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BigramConfig:\n",
        "    root_dir: str = os.getcwd() + \"/../../\"\n",
        "    dataset_path: str = \"names.txt\"\n",
        "\n",
        "    # Tokenizer\n",
        "    vocab_size: int = 0  # Set later\n",
        "\n",
        "    seed: int = 101\n",
        "\n",
        "config = BigramConfig()"
      ],
      "id": "ef1253f6800c36c1",
      "outputs": [],
      "execution_count": 9
    },
    {
      "metadata": {
        "id": "5726a09b7e375389"
      },
      "cell_type": "markdown",
      "source": [
        "## Reproducibility"
      ],
      "id": "5726a09b7e375389"
    },
    {
      "metadata": {
        "id": "5e4d38445588cdbb",
        "outputId": "73dac938-210a-4921-d4bb-f5625c4a3f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "set_seed(config.seed)"
      ],
      "id": "5e4d38445588cdbb",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set to 101\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "metadata": {
        "id": "d74be7e01434a14b"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "id": "d74be7e01434a14b"
    },
    {
      "metadata": {
        "id": "32e86ea6f15f11b8",
        "outputId": "4a838583-3cbf-40e4-c665-99de8f7493d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "names = load_text(config.dataset_path).splitlines()"
      ],
      "id": "32e86ea6f15f11b8",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded text data from names.txt (length: 228145 characters).\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "metadata": {
        "id": "3aff6f7e1bbade4"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "id": "3aff6f7e1bbade4"
    },
    {
      "metadata": {
        "id": "ed24c0db0ce9da98"
      },
      "cell_type": "code",
      "source": [
        "# Add special token\n",
        "names = [\".\" + name + \".\" for name in names]"
      ],
      "id": "ed24c0db0ce9da98",
      "outputs": [],
      "execution_count": 11
    },
    {
      "metadata": {
        "id": "f9e38655c11342dd"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "id": "f9e38655c11342dd"
    },
    {
      "metadata": {
        "id": "9a2f768e619dfb02"
      },
      "cell_type": "code",
      "source": [
        "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
        "chars.insert(0, \".\")  # Add special token\n",
        "config.vocab_size = len(chars)\n",
        "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx2str = {idx: char for char, idx in str2idx.items()}"
      ],
      "id": "9a2f768e619dfb02",
      "outputs": [],
      "execution_count": 12
    },
    {
      "metadata": {
        "id": "91e4e1dda633584d"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "id": "91e4e1dda633584d"
    },
    {
      "metadata": {
        "id": "523dd8edb6b3e9c8"
      },
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "W = torch.randn(config.vocab_size, config.vocab_size, requires_grad=True)\n",
        "b = torch.randn(config.vocab_size, requires_grad=True)\n",
        "params = [W, b]"
      ],
      "id": "523dd8edb6b3e9c8",
      "outputs": [],
      "execution_count": 13
    },
    {
      "metadata": {
        "id": "51ca7979aafb68a"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "id": "51ca7979aafb68a"
    },
    {
      "metadata": {
        "id": "bd6125c93c9c7519"
      },
      "cell_type": "markdown",
      "source": [
        "#### Task 1: Train Bigram Language Model (Neural Network Approach)\n",
        "\n",
        "Make the training loop for the Bigram Language Model."
      ],
      "id": "bd6125c93c9c7519"
    },
    {
      "metadata": {
        "id": "f8f5165e72e37f1b"
      },
      "cell_type": "code",
      "source": [
        "# Set of Input, Target pairs\n",
        "inputs, targets = [], []\n",
        "for name in names:\n",
        "    for char1, char2 in zip(name, name[1:]):\n",
        "        input = str2idx[char1]\n",
        "        target = str2idx[char2]\n",
        "        inputs.append(input)\n",
        "        targets.append(target)\n",
        "\n",
        "# Convert to tensor\n",
        "inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)"
      ],
      "id": "f8f5165e72e37f1b",
      "outputs": [],
      "execution_count": 14
    },
    {
      "metadata": {
        "id": "ebe57ba03f098d90",
        "outputId": "3fa8aea2-23ec-4067-c128-a47f5b4ef605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Number of Input, Target pairs: {len(inputs)}\")\n",
        "print(f\"Input shape: {inputs.shape}\")\n",
        "print(f\"Target shape: {targets.shape}\")\n",
        "print(f\"First (Input, Target): ({inputs[0]}, {targets[0]})\")\n",
        "print(f\"Second (Input, Target): ({inputs[1]}, {targets[1]})\")"
      ],
      "id": "ebe57ba03f098d90",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Input, Target pairs: 228146\n",
            "Input shape: torch.Size([228146])\n",
            "Target shape: torch.Size([228146])\n",
            "First (Input, Target): (0, 5)\n",
            "Second (Input, Target): (5, 13)\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "metadata": {
        "id": "4baab50fd5515e6a"
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# One-hot encode the input tensor.                                             #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "inputs_encoded = F.one_hot(inputs, num_classes=config.vocab_size)\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "# Convert data type to float\n",
        "inputs_encoded = inputs_encoded.float()"
      ],
      "id": "4baab50fd5515e6a",
      "outputs": [],
      "execution_count": 18
    },
    {
      "metadata": {
        "id": "1a5ef07b0b820e5a",
        "outputId": "fee35d96-f60d-45ea-8960-02d0145152be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "steps = 100\n",
        "lr = 10\n",
        "\n",
        "for step in range(1, steps + 1):\n",
        "    # Forward pass\n",
        "    ################################################################################\n",
        "    # TODO:                                                                        #\n",
        "    # Implement the forward pass.                                                  #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    logits = inputs_encoded @ W + b\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    # loss\n",
        "    log_probs = torch.log(probs + 1e-9)  # Add small value to prevent log(0)\n",
        "    loss = -log_probs[torch.arange(len(targets)), targets].mean()\n",
        "\n",
        "    # Backward pass\n",
        "    ################################################################################\n",
        "    # TODO:                                                                        #\n",
        "    # Implement the backward pass.                                                 #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    for param in params:\n",
        "        if param.grad is not None:\n",
        "            param.grad.zero_()\n",
        "    loss.backward()\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    # Update weights\n",
        "    ################################################################################\n",
        "    # TODO:                                                                        #\n",
        "    # Update the weights of the model using the gradients.                         #\n",
        "    ################################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    with torch.no_grad():\n",
        "        for param in params:\n",
        "            param -= lr * param.grad\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"Step {step}, Loss {loss.item():.4f}\")"
      ],
      "id": "1a5ef07b0b820e5a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10, Loss 2.8777\n",
            "Step 20, Loss 2.7156\n",
            "Step 30, Loss 2.6413\n",
            "Step 40, Loss 2.5989\n",
            "Step 50, Loss 2.5718\n",
            "Step 60, Loss 2.5532\n",
            "Step 70, Loss 2.5397\n",
            "Step 80, Loss 2.5294\n",
            "Step 90, Loss 2.5214\n",
            "Step 100, Loss 2.5150\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "metadata": {
        "id": "4d956fef0a027963"
      },
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "id": "4d956fef0a027963"
    },
    {
      "metadata": {
        "id": "786f852b486b92cb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Task 2: Generate a Name\n",
        "\n",
        "Create a function to generate a name using the trained Bigram Language Model."
      ],
      "id": "786f852b486b92cb"
    },
    {
      "metadata": {
        "id": "b31dfacd08b51cd3",
        "outputId": "197f4bbc-7ae0-4f85-94d1-f5a5221ac4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a function to generate a name\n",
        "def generate_name():\n",
        "    new_name = []\n",
        "    start_idx = str2idx[\".\"]\n",
        "\n",
        "    while True:\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # 1. Forward pass                                                              #\n",
        "        # 2. Sample the next token                                                     #\n",
        "        # 3. Decode the token                                                          #\n",
        "        # 4. Update the start_idx                                                      #\n",
        "        # 5. Break if the next character is \".\"                                        #\n",
        "        ################################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        # Forward pass\n",
        "        x = F.one_hot(torch.tensor([start_idx]), num_classes=config.vocab_size).float()\n",
        "        logits = x @ W + b\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        # Sample\n",
        "        next_idx = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "        # Decode\n",
        "        next_char = idx2str[next_idx]\n",
        "\n",
        "        # Update\n",
        "        if next_char == \".\":\n",
        "            break\n",
        "        new_name.append(next_char)\n",
        "\n",
        "        # Break if \".\"\n",
        "        start_idx = next_idx\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    return ''.join(new_name)\n",
        "\n",
        "# Generate 5 names\n",
        "for _ in range(5):\n",
        "    print(generate_name())"
      ],
      "id": "b31dfacd08b51cd3",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aymienzeta\n",
            "dhchatt\n",
            "rneara\n",
            "gn\n",
            "todeleanion\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "metadata": {
        "id": "11d00faaddbe4b44"
      },
      "cell_type": "markdown",
      "source": [
        "## Extra Credit\n",
        "\n",
        "We have already made our own custom auto-grad Tensor class. Let's use it!\n",
        "\n",
        "Train the Bigram Language Model using our custom auto-grad Tensor class.\n",
        "\n",
        "**Do not use any built-in PyTorch functions.** (other deep learning libraries are also prohibited)"
      ],
      "id": "11d00faaddbe4b44"
    },
    {
      "metadata": {
        "id": "e6f26efc1212bb48"
      },
      "cell_type": "code",
      "source": [
        "class Tensor:\n",
        "    def __init__(self, data, _children=(), _operation=''):\n",
        "        self.data = data\n",
        "        self._prev = set(_children)\n",
        "        self.gradient = 0\n",
        "        self._backward = lambda: None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"tensor=({self.data})\"\n",
        "\n",
        "    def __add__(self, other):  # self + other\n",
        "        output = Tensor(self.data + other.data, (self, other), '+')\n",
        "        def _backward():\n",
        "            self.gradient = 1 * output.gradient\n",
        "            other.gradient = 1 * output.gradient\n",
        "        output._backward = _backward\n",
        "        return output\n",
        "\n",
        "    def __mul__(self, other):  # self * other\n",
        "        output = Tensor(self.data * other.data, (self, other), '*')\n",
        "        def _backward():\n",
        "            self.gradient = other.data * output.gradient\n",
        "            other.gradient = self.data * output.gradient\n",
        "        output._backward = _backward\n",
        "        return output\n",
        "\n",
        "    def tanh(self):  # tanh(self)\n",
        "        output = Tensor(math.tanh(self.data), (self,), 'tanh')\n",
        "        def _backward():\n",
        "            self.gradient = (1.0 - math.tanh(self.data) ** 2) * output.gradient\n",
        "        output._backward = _backward\n",
        "        return output\n",
        "\n",
        "    def __pow__(self, power):  # self ** power\n",
        "        assert isinstance(power, (int, float)), \"Power must be an int or a float\"\n",
        "        output = Tensor(self.data ** power, (self,), f'**{power}')\n",
        "        def _backward():\n",
        "            self.gradient = power * (self.data ** (power - 1)) * output.gradient\n",
        "        output._backward = _backward\n",
        "        return output\n",
        "\n",
        "    def backward(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "        build_topo(self)\n",
        "        self.gradient = 1\n",
        "        for node in reversed(topo):\n",
        "            node._backward()\n",
        "\n",
        "    def __neg__(self): # -self\n",
        "        return self * Tensor(-1.0)\n",
        "\n",
        "    def __sub__(self, other): # self - other\n",
        "        return self + (-other)"
      ],
      "id": "e6f26efc1212bb48",
      "outputs": [],
      "execution_count": 21
    },
    {
      "metadata": {
        "id": "e3b7815ada66df8c",
        "outputId": "312917db-0c95-48af-e658-84acff75171d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "import random\n",
        "import math\n",
        "\n",
        "# 데이터셋: 문자 사전 생성 (a-z + \".\")\n",
        "chars = ['.'] + [chr(i) for i in range(97, 123)]\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# 문자 → 인덱스 변환\n",
        "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx2str = {idx: char for char, idx in str2idx.items()}\n",
        "\n",
        "# 훈련 데이터 준비\n",
        "names = [\"hello\", \"world\", \"chat\", \"bot\"]\n",
        "names = [\".\" + name + \".\" for name in names]  # 시작과 끝을 '.'으로 감싸기\n",
        "\n",
        "# 빅램 (Bigram) 데이터셋 생성\n",
        "inputs, targets = [], []\n",
        "for name in names:\n",
        "    for ch1, ch2 in zip(name, name[1:]):\n",
        "        inputs.append(str2idx[ch1])\n",
        "        targets.append(str2idx[ch2])\n",
        "\n",
        "# 커스텀 Tensor 클래스를 사용한 가중치 초기화\n",
        "W = [[Tensor(random.uniform(-1, 1)) for _ in range(vocab_size)] for _ in range(vocab_size)]\n",
        "b = [Tensor(random.uniform(-1, 1)) for _ in range(vocab_size)]\n",
        "\n",
        "# 확률 계산을 위한 소프트맥스 함수\n",
        "def softmax(logits):\n",
        "    exps = [math.exp(logit.data) for logit in logits]  # e^x\n",
        "    total = sum(exps)  # Tensor 덧셈 사용\n",
        "    return [Tensor(exp / total) for exp in exps]\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "epochs = 500\n",
        "lr = 0.1\n",
        "\n",
        "# 훈련 루프\n",
        "for epoch in range(epochs):\n",
        "    # 순전파 (Forward)\n",
        "    loss = Tensor(0.0)\n",
        "    for i in range(len(inputs)):\n",
        "        x = inputs[i]\n",
        "        y = targets[i]\n",
        "\n",
        "        # 선형 변환: logits = W[x] + b\n",
        "        logits = [W[x][j] + b[j] for j in range(vocab_size)]\n",
        "\n",
        "        probs = softmax(logits)\n",
        "\n",
        "        # Cross-Entropy Loss 대체 (로그 없이)\n",
        "        loss = loss + -(probs[y].tanh())  # 확률 값 자체를 사용하여 손실 계산\n",
        "\n",
        "    # 🎯 역전파 (Backward)\n",
        "    loss.backward()\n",
        "\n",
        "    # 🔄 SGD 업데이트\n",
        "    for i in range(vocab_size):\n",
        "        for j in range(vocab_size):\n",
        "            W[i][j] = W[i][j] - Tensor(lr) * Tensor(W[i][j].gradient)\n",
        "        b[i] = b[i] - Tensor(lr) * Tensor(b[i].gradient)\n",
        "\n",
        "    # 🖥️ 학습 진행 출력\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.data:.4f}\")\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
      ],
      "id": "e3b7815ada66df8c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: -0.7923\n",
            "Epoch 50, Loss: -0.7923\n",
            "Epoch 100, Loss: -0.7923\n",
            "Epoch 150, Loss: -0.7923\n",
            "Epoch 200, Loss: -0.7923\n",
            "Epoch 250, Loss: -0.7923\n",
            "Epoch 300, Loss: -0.7923\n",
            "Epoch 350, Loss: -0.7923\n",
            "Epoch 400, Loss: -0.7923\n",
            "Epoch 450, Loss: -0.7923\n"
          ]
        }
      ],
      "execution_count": 39
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}