{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Assignment 3\n",
    "\n",
    "In this assignment, you will refactor the code from the lecture by...\n",
    "1. Adding a train-validation split.\n",
    "2. Using `nn.Module` for defining the model.\n",
    "3. Implementing the training loop."
   ],
   "id": "1d8158dfddb2ac72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "e74cf4f768c1edcc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from utils import load_text, set_seed, configure_device\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "2cb2cbcb0169f77d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note:** If you do not have a GPU, decrease the `max_steps`",
   "id": "3f8bfe28c1af6b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class MLPConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "    \n",
    "    # Model\n",
    "    context_size: int = 3\n",
    "    d_embed: int = 16\n",
    "    d_hidden: int = 64\n",
    "    \n",
    "    # Training\n",
    "    val_size: float = 0.1\n",
    "    batch_size: int = 32\n",
    "    max_steps: int = 10000\n",
    "    lr: float = 2e-3\n",
    "    val_interval: int = 1000\n",
    "\n",
    "    seed: int = 101\n",
    "    \n",
    "config = MLPConfig()"
   ],
   "id": "f87ea90a462f04bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "21388a355d7684a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "set_seed(config.seed)\n",
    "generator = torch.Generator().manual_seed(config.seed)"
   ],
   "id": "c978c462c20bd1aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "7de6979c114cc847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "config.device = configure_device()",
   "id": "a9ca76989a82c131",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenizer",
   "id": "fd06cd53a8099029"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "config.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ],
   "id": "3ec4919298103e29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "143169f16782a55f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "names = load_text(config.root_dir + config.dataset_path).splitlines()",
   "id": "e8acd205ab399fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "908b723455adc6b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1: Train-Validation split\n",
    "\n",
    "Using all the data for training leads to overfitting.\n",
    "\n",
    "Implement a function to split the text into training and validation sets. "
   ],
   "id": "a8ce74000c6911e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_names(_names: str, val_size: float) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Split text into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        _names (str): The data to split.\n",
    "        val_size (float): Size of the validation set.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: Training and validation data.\n",
    "    \"\"\"\n",
    "    if val_size <= 0 or val_size >= 1:\n",
    "        raise ValueError(f\"Invalid validation size: {val_size}\")\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Split the data into training and validation sets.                            #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return train_text, val_text"
   ],
   "id": "7d442ad0a2d2a836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_names, val_names = split_names(names, config.val_size)\n",
    "print(f\"Training set size: {len(train_names)}\")\n",
    "print(f\"Validation set size: {len(val_names)}\")"
   ],
   "id": "fd12c70f91c99915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_dataset(_names):\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    for name in _names:\n",
    "        context = [0] * config.context_size\n",
    "        \n",
    "        for char in name + \".\":\n",
    "            idx = str2idx[char]\n",
    "            inputs.append(context)\n",
    "            targets.append(idx)\n",
    "            context = context[1:] + [idx]  # Shift the context by 1 character\n",
    "\n",
    "    inputs = torch.tensor(inputs)\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    return inputs, targets"
   ],
   "id": "6d20c3c432239094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_inputs, train_targets = prepare_dataset(train_names)\n",
    "val_inputs, val_targets = prepare_dataset(val_names)"
   ],
   "id": "753ed8355d96dd30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "3afb919d68490621"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2: `nn.Module`.\n",
    "\n",
    "PyTorch provides a module called `nn.Module` for defining models. Instead of defining every layer as a separate tensor, we can wrap it all up in a class. This provides better organization and encapsulation.\n",
    "\n",
    "[PyTorch Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
    "\n",
    "Implement a class `MLP` that inherits from `nn.Module`.\n",
    "(Hint: You can use `nn.Embedding` and `nn.Linear`)\n"
   ],
   "id": "3b30b401056e9d88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Define the __init__ and forward methods for the MLP model.                   #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    # Note: do not include softmax in the forward pass since it is already included in the loss function."
   ],
   "id": "a56fae6095a01da9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "mlp = MLP(config.vocab_size, config.context_size, config.d_embed, config.d_hidden)\n",
    "mlp.to(config.device) # Move the model to the device\n",
    "print(mlp)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in mlp.parameters()))\n",
    "\n",
    "# Example forward pass\n",
    "example_input = train_inputs[:2]\n",
    "example_input = example_input.to(config.device)  # Move the data to the device\n",
    "print(f\"Input shape: {example_input.shape}\")\n",
    "print(f\"Output shape: {mlp(example_input).shape}\")"
   ],
   "id": "1145b4db700ccaf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "424042449c0aa770"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 3: Training loop.\n",
    "\n",
    "Implement the training loop for the model.\n",
    "\n",
    "What is an optimizer? [PyTorch Documentation](https://pytorch.org/docs/stable/optim.html)"
   ],
   "id": "97b460fa44e187b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train(model):\n",
    "    steps = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Define the optimizer\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Define the optimizer for the model.                                          #\n",
    "    # Use stochastic gradient descent (SGD) with the learning rate from the config.#\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    for step in range(1, config.max_steps + 1):\n",
    "        # Training\n",
    "        # Sample batch\n",
    "        idx = torch.randperm(len(train_inputs))[:config.batch_size]\n",
    "        x, y = train_inputs[idx], train_targets[idx]\n",
    "        x, y = x.to(config.device), y.to(config.device)  # Move the data to the device\n",
    "        \n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Implement the forward pass and the backward pass                             #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # Forward pass\n",
    "        \n",
    "        \n",
    "        # Backward pass\n",
    "        \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "        # Validation\n",
    "        if step % config.val_interval == 0:\n",
    "            # Validation loss\n",
    "            with torch.no_grad():\n",
    "                val_logits = model(val_inputs.to(config.device))\n",
    "                val_loss = F.cross_entropy(val_logits, val_targets.to(config.device)).item()\n",
    "                val_losses.append(val_loss)\n",
    "            \n",
    "        # Logging\n",
    "        steps.append(step)\n",
    "        train_losses.append(loss.item())\n",
    "        if step % config.val_interval == 0:\n",
    "            print(f\"Step {step}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Plot the loss\n",
    "    plt.figure()\n",
    "    plt.plot(steps, train_losses, label=\"Train\")\n",
    "    plt.plot(steps[::config.val_interval], val_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "34c5737ae1ca96d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train(mlp)",
   "id": "88b77b52fc6bd791",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inference",
   "id": "5d2880695e69f27e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_name():\n",
    "    new_name = []\n",
    "    context = [0] * config.context_size\n",
    "    \n",
    "    while True:\n",
    "        # forward pass\n",
    "        x = torch.tensor(context).unsqueeze(0).to(config.device)\n",
    "        logits = mlp(x)\n",
    "        \n",
    "        # sample\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "        # update context\n",
    "        new_name.append(idx2str[idx])\n",
    "        context = context[1:] + [idx]\n",
    "        \n",
    "        # break if \".\"\n",
    "        if idx == 0:\n",
    "            break\n",
    "        \n",
    "    return \"\".join(new_name)"
   ],
   "id": "254cfa9b9167cecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _ in range(5):\n",
    "    print(generate_name())"
   ],
   "id": "18536bfec99f36ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extra Credit\n",
    "\n",
    "Change the model configuration and hyperparameters to achieve the following:\n",
    "\n",
    "Generate good-looking names and get the lowest **validation loss** as possible.\n",
    "\n",
    "Rules:\n",
    "- Do not change the random seed.\n",
    "- Do not change the validation set size.\n",
    "- External data is not allowed."
   ],
   "id": "5672f33432bc5671"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
